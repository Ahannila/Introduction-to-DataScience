{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science 2025\n",
    "\n",
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 | Matrix warm-up\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in the course material.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful properties of any scientific programming language (Python with NumPy, R, Julia, etc) is that they allow us to work with matrices efficiently. Let's learn more about these features!\n",
    "\n",
    "### 1.1 Basics\n",
    "\n",
    "1. Let's start by creating two arrays <span style=\"background-color: #ccfff2\"> A</span> and <span style=\"background-color: #ccfff2\"> B</span> which each have the integers <span style=\"background-color: #ccfff2\"> 0, 1, 2, ..., 1e7-1</span>. Use the normal arrays or lists of the programming language you are using, e.g. *list* or *[ ]* or *numpy.array()* in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use this cell for your code\n",
    "import numpy as np\n",
    "\n",
    "A = list(range(1, int(1e7-1)))\n",
    "B = list(range(1, int(1e7-1)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that uses a <span style=\"background-color: #ccfff2\"> for loop</span> or equivalent to return a new array <span style=\"background-color: #ccfff2\"> C</span>, which contains the <span style=\"background-color: #ccfff2\"> element-wise sum of *A* and *B*</span>, e.g. C should contain the integers <span style=\"background-color: #ccfff2\"> 0, 2, 4, etc</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_with_for(A,B):\n",
    "    C = []\n",
    "    for n in range(len(A)):\n",
    "        C.append(A[n] + B[n])\n",
    "    return C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, let's create another function that uses NumPy (or equivalent) to do the same. To try it out, allocate two arrays (e.g. using <span style=\"background-color: #ccfff2\"> np.array</span> in NumPy) and add the arrays together using your function. Don't use loops, instead, find out how to add the two arrays directly. What do you notice in comparison to the previous function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       2        4        6 ... 19999992 19999994 19999996]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "A_np = np.array(A)\n",
    "B_np = np.array(B)\n",
    "\n",
    "d = A_np + B_np\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #ccfff2\"> *Note: for the following exercises, only use NumPy or equivalent functions. Don't use any loops.* </span>\n",
    "1. Create the following array:\n",
    "\n",
    "*[hint: <span style=\"background-color: #ccfff2\"> np.reshape</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
    "#        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "#        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "#        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "#        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "#        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "#        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "#        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "#        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
    "#        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "array = np.arange(100).reshape(10,10)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      " [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "array1 = np.tile([0.,1.,], (10,5))\n",
    "s = np.array2string(array1, separator=', ')\n",
    "print(f'array({s})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the following array (D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "n = 10\n",
    "D = np.ones((n, n)) - np.eye(n)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the following array (E):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "n = 10\n",
    "E = np.ones((n, n)) - np.fliplr(np.eye(n))\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Call the last two matrices <span style=\"background-color: #ccfff2\">D</span> and <span style=\"background-color: #ccfff2\">E</span>, respectively. Show that the determinant of their product (matrix multiplication) is the same as the product of their determinants. That is calculate both <span style=\"background-color: #ccfff2\">det(DE)</span> and <span style=\"background-color: #ccfff2\">det(D) * det(E)</span>, and show that they are the same. Is it a coincidence? (I think not) The product of the determinants (or the determinant of the product) should be -81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-81.0\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "det_D = np.linalg.det(D)\n",
    "det_E = np.linalg.det(E)\n",
    "det_DE = np.linalg.det(D @ E)\n",
    "prod_det = det_D * det_E\n",
    "\n",
    "print(prod_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *Use this markdown cell for your written answer* --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Slicing\n",
    "\n",
    "Array slicing is a powerful way to extract data from an array. Let's practice array slicing with the following exercises!\n",
    "\n",
    "1. Load the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). The data should be a matrix of shape <span style=\"background-color: #ccfff2\">(20640, 8)</span>, that is 20640 rows and 8 columns. Use the <span style=\"background-color: #ccfff2\">.shape</span> attribute of NumPy arrays to verify this. Here's a [description of the fields](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select rows where the average number of bedrooms <span style=\"background-color: #ccfff2\">(AveBedrms)</span> is higher than 2. The first few row indices should be <span style=\"background-color: #ccfff2\">710,  1023,  1024, ...</span> (zero-indexed). Count these houses - how many rows are selected? *[hint: <span style=\"background-color: #ccfff2\">np.where</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  710,  1023,  1024,  1030,  1102,  1233,  1234,  1235,  1236,\n",
      "        1238,  1239,  1240,  1566,  1867,  1871,  1872,  1879,  1881,\n",
      "        1889,  1901,  1906,  1910,  1911,  1912,  1913,  1914,  1925,\n",
      "        1926,  1978,  1979,  2392,  2395,  2396,  2397,  2398,  2510,\n",
      "        2511,  2643,  2656,  2763,  2768,  2776,  2778,  3014,  3086,\n",
      "        3095,  3258,  3292,  3293,  3313,  3314,  3334,  3349,  3350,\n",
      "        9193,  9423,  9431,  9451,  9634,  9669,  9671,  9672,  9675,\n",
      "        9676,  9678,  9679,  9680,  9681,  9682,  9683, 10067, 10076,\n",
      "       10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10405,\n",
      "       11705, 11706, 11707, 11708, 11709, 11710, 11711, 11713, 11714,\n",
      "       11715, 11716, 11717, 11719, 11720, 11721, 11722, 11723, 11724,\n",
      "       11725, 11729, 11831, 11832, 11833, 11834, 11847, 11848, 11849,\n",
      "       11850, 11862, 11865, 11866, 11867, 11869, 11870, 12136, 12303,\n",
      "       12305, 12306, 12307, 12324, 12325, 12344, 12349, 12351, 12354,\n",
      "       12359, 12361, 12362, 12366, 12368, 12371, 12372, 12374, 12376,\n",
      "       12390, 12392, 12394, 12396, 12404, 12405, 12430, 12446, 12447,\n",
      "       13898, 13900, 13911, 13912, 13919, 13920, 13923, 13924, 13934,\n",
      "       13935, 13936, 13937, 13939, 13940, 13941, 13942, 13943, 13944,\n",
      "       13945, 13946, 13947, 13948, 13949, 13950, 13953, 13954, 13955,\n",
      "       13956, 13957, 13958, 13959, 13960, 13961, 13962, 13963, 13964,\n",
      "       13965, 13966, 13967, 13968, 13969, 13970, 13971, 13972, 13973,\n",
      "       13974, 13975, 13976, 13978, 13979, 13980, 13999, 14417, 14418,\n",
      "       14805, 15500, 15595, 15779, 16598, 17878, 17891, 18680, 18681,\n",
      "       18817, 18821, 18822, 18858, 19331, 19362, 19435, 19536, 19736,\n",
      "       19780, 19781, 19789, 19800, 19801, 19802, 19803, 19806, 19807,\n",
      "       19975, 19976, 19977, 20089, 20092, 20093, 20094, 20110, 20112,\n",
      "       20113]),)\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "res = np.where(X[:, 3] > 2)\n",
    "print(res)\n",
    "print(len(res[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select the rows where the median house age (i.e. median in each block group) <span style=\"background-color: #ccfff2\">(HouseAge)</span> is between 1 and 3 years (inclusive). There should be **124** of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "res = np.where((X[:, 1] >= 1 ) & (X[:, 1] <= 3))\n",
    "print(len(res[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the mean of the block group population <span style=\"background-color: #ccfff2\">(Population)</span> for homes whose median value is more than 25000 USD (the target variable). It should be around **1425.68**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425.6833737275813\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "y = housing.target\n",
    "mask = y > 0.25\n",
    "res = X[mask, 4]\n",
    "res = np.mean(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 | Working with text data\n",
    "\n",
    "Next, let's look into some text data. We will be looking into Amazon reviews, and the necessary steps to transform a raw dataset into a format more suitable for prediction tasks.\n",
    "\n",
    "1. Download the automotive 5-core dataset from [here](https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Automotive_5.json.gz). Next, you can extract the data in <span style=\"background-color: #ccfff2\">JSON</span> format. You can also download one of the bigger ones, if you are feeling ambitious. Open the JSON file. Access the <span style=\"background-color: #ccfff2\">reviewText</span> field, which contains the unstructured review text written by the user.\n",
    "\n",
    "For instance, the first review reads as follows: \n",
    "\n",
    "*'After I wrote the below review, the manufacturer contacted me and explained how to use this.  Instead of the (current) picture on Amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally. [...]'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code\n",
    "import json\n",
    "\n",
    "filepath = 'Automotive_5.json'\n",
    "data = []\n",
    "with open(filepath, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "     \n",
    "\n",
    "\n",
    "print(data[0][\"reviewText\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's follow some steps to normalize the text data.\n",
    "\n",
    "When dealing with natural language, it is important to notice that while, for example, the words \"Copper\" and \"copper\" are represented by two different strings, they have the same meaning. When applying statistical methods on this data, it is useful to ensure that words with the same meaning are represented by the same string.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Downcasing</span>: Let's first downcase the contents of the <span style=\"background-color: #ccfff2\">reviewText</span> field.\n",
    "\n",
    "Now the first review should be:\n",
    "\n",
    "*'after i wrote the below review, the manufacturer contacted me and explained how to use this.  instead of the (current) picture on amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after i wrote the below review, the manufacturer contacted me and explained how to use this.  instead of the (current) picture on amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally.  then the charge / sync cable goes through the hole and you can charge from the side.  when used in landscape position this stand does make more sense so i'm upgrading this review from 2 stars to 4 stars (which i rarely do, but in this case user error) with a star off for lack of documentation.  manufacturer has said he will include directions and i would also encourage him to update the photos on amazon with more examples of how this can be used.  the wood quality is indeed good and it's a sturdy little stand.  i'm trying to think of when i'd actually use this stand... perhaps for facetime chats.  i also think it would be useful for someone in an open office environment if they want to keep their phone on their desk and see alerts / notifications easily.  hope this updated review helps.\n",
      "\n",
      "original review:\n",
      "i am throwing this stand in the garbage.  while it's crafted of a nice wood, it is not functional as near as i can tell.  it does not come with instructions and as you can see from the product description, even that is confusing since the english is poorly translated chinese.  the iphone sits on the stand just fine, but when it's on the stand, there is no way the plug on the bottom  will plug in -- the stand blocks it.  if you turn the iphone over, the plug is on the top, which just looks strange.  and i'm not at all sure what the hole in the back of the stand is supposed to do.  also included are four plastic feet, again no instructions, so i affixed them to the bottom of the stand and it began to wobble.\n",
      "\n",
      "perhaps someone else will figure out how to work this thing and post a review, but as far as i'm concerned, the out of the box experience was terrible.\n",
      "\n",
      "sorry, i cannot recommend.\n",
      "\n",
      "sample provided in exchange for an honest review.\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "reviews = [d[\"reviewText\"] for d in data if \"reviewText\" in d]\n",
    "\n",
    "reviews = [r.lower() for r in reviews]  \n",
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's continue with punctuation and stop word removal. Stop words are words like \"and\", \"the\", etc. They are usually very common words that have little to do with the actual content matter. There's plenty openly available lists of stop words for almost any (natural) language.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Punctuation and stop-word removal</span>: Let's now remove all punctuation, as well as the stop words. You can find a stop word list for English, e.g. [here](https://gist.github.com/xldrkp/4a3b1a33f10d37bedbe0068f2b4482e8#file-stopwords-en-txt).*(use the link to download a txt of english stopwords)* Save the stopwords in the file as \"stopwords-en.txt\".\n",
    "\n",
    "First review at this point reads as: \n",
    "\n",
    "*'wrote review manufacturer contacted explained current picture amazon phone vertically stand phone horizontally'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote review manufacturer contacted explained current picture amazon phone placed vertically actually stand phone placed horizontally charge sync cable goes hole charge used landscape position stand does make sense m upgrading review stars stars rarely case user error star lack documentation manufacturer said include directions encourage update photos amazon examples used wood quality good s sturdy little stand m trying think d actually stand facetime chats think useful open office environment want phone desk alerts notifications easily hope updated review helps original review throwing stand garbage s crafted nice wood functional near tell does come instructions product description confusing english poorly translated chinese iphone sits stand just fine s stand way plug plug stand blocks turn iphone plug just looks strange m sure hole stand supposed included plastic feet instructions affixed stand began wobble figure work thing post review far m concerned box experience terrible sorry recommend sample provided exchange honest review\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "import re\n",
    "reviews = [re.sub(r\"[^a-z\\s]\", \" \", r) for r in reviews]      \n",
    "with open(\"stopwords-en.txt\", \"r\") as f:\n",
    "    stopwords = set(w.strip().lower() for w in f if w.strip())\n",
    "\n",
    "reviews = [\n",
    "    \" \".join([word for word in r.split() if word not in stopwords])\n",
    "    for r in reviews\n",
    "]\n",
    "\n",
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's continue with stemming. For example, while the words \"swims\" and \"swim\" are different strings, they both refer to swimming. [Stemming](https://en.wikipedia.org/wiki/Stemming) refers to the process of mapping words from their inflected form to their base form, for instance: swims -> swim.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Stemming</span>: Apply a stemmer on the paragraphs, so that inflected forms are mapped to the base form. For example, for Python the popular natural language toolkit [nltk](http://www.nltk.org/howto/stem.html) has an easy to use stemmer. In case you are using R, you can try the [Snowball stemmer](https://www.rdocumentation.org/packages/corpus/versions/0.10.2/topics/stem_snowball). You can find out how to install nltk from [here](https://www.nltk.org/install.html). It will take a while to run! So, grab a coffee and wait :D\n",
    "\n",
    "Finally, after stemming: \n",
    "\n",
    "*'wrote review manufactur contact explain current pictur amazon phone vertic stand phone horizont'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/haarhaar/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stemming: wrote review manufactur contact explain current pictur amazon phone place vertic actual stand phone place horizont charg sync cabl goe hole charg use landscap posit stand doe make sens m upgrad review star star rare case user error star lack document manufactur said includ direct encourag updat photo amazon exampl use wood qualiti good s sturdi littl stand m tri think d actual stand facetim chat think use open offic environ want phone desk alert notif easili hope updat review help origin review throw stand garbag s craft nice wood function near tell doe come instruct product descript confus english poorli translat chines iphon sit stand just fine s stand way plug plug stand block turn iphon plug just look strang m sure hole stand suppos includ plastic feet instruct affix stand began wobbl figur work thing post review far m concern box experi terribl sorri recommend sampl provid exchang honest review\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "from nltk.stem import*\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "stemmer = PorterStemmer()\n",
    "reviews = [\n",
    "    \" \".join([stemmer.stem(word) for word in r.split()])\n",
    "    for r in reviews\n",
    "]\n",
    "\n",
    "print(\"After stemming:\", reviews[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, filter the data by selecting reviews where the field <span style=\"background-color: #ccfff2\">overall</span> is 4 or 5, and store the review texts in a file named <span style=\"background-color: #ccfff2\">pos.txt</span>. Similarly, select reviews with rating 1 or 2 and store them in a file named <span style=\"background-color: #ccfff2\">neg.txt</span>. Ignore the reviews with overall rating 3. Each line in the two files should contain exactly one preprocessed review text without the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 1470185 lines to pos.txt and 132123 lines to neg.txt. Skipped: 5945.\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "\n",
    "pos_path = \"pos.txt\"\n",
    "neg_path = \"neg.txt\"\n",
    "\n",
    "pos_out = open(pos_path, \"w\", encoding=\"utf-8\")\n",
    "neg_out = open(neg_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "skipped = 0\n",
    "\n",
    "i = 0  \n",
    "\n",
    "for d in data:\n",
    "    if \"reviewText\" not in d:\n",
    "        continue  \n",
    "    text = reviews[i].strip()\n",
    "    i += 1  \n",
    "    if not text:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if \"overall\" not in d:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        rating = int(d[\"overall\"])\n",
    "    except Exception:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if rating == 3:\n",
    "        continue  \n",
    "\n",
    "    if rating >= 4:\n",
    "        pos_out.write(text + \"\\n\")\n",
    "        pos_count += 1\n",
    "    elif rating <= 2:\n",
    "        neg_out.write(text + \"\\n\")\n",
    "        neg_count += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "pos_out.close()\n",
    "neg_out.close()\n",
    "\n",
    "print(f\"Done. Wrote {pos_count} lines to {pos_path} and {neg_count} lines to {neg_path}. Skipped: {skipped}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 | SQL basics\n",
    "\n",
    "Next, let's take a refresher on the basics of SQL. In this exercise, you will be working on the simplified Northwind 2000 SQLite database. You can download the database from Kaggle [here](https://courses.mooc.fi/api/v0/files/course/f92ffc32-2dd4-421d-87f3-c48800422cc5/files/VEKX2bxGCDGyojG902gmYZTXCnrAQw.zip).\n",
    "\n",
    "To test your SQL queries and complete the exercise, you can download and install SQLite if you don't yet have it installed.\n",
    "\n",
    "Please write SQL queries for the tasks on the simplified Northwind 2000 SQLite database.\n",
    "\n",
    "1. List the first name, last name, and hire date of all employees hired after January 1st, 1994.\n",
    "\n",
    "2. Count how many orders each customer has placed.\n",
    "\n",
    "3. Find the names of all customers who have ordered the product \"Chai\".\n",
    "\n",
    "4. Find all orders that have been placed but not yet shipped.\n",
    "\n",
    "5. Find the customer who has placed the most orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\n",
    "sqlite> SELECT FirstName, Lastname, HireDate FROM Employees WHERE HireDate > '1994-01-01' ORDER BY HireDate;\n",
    "FirstName  LastName   HireDate  \n",
    "---------  ---------  ----------\n",
    "Robert     King       1994-01-02\n",
    "Laura      Callahan   1994-03-05\n",
    "Anne       Dodsworth  1994-11-15\n",
    "2.\n",
    "sqlite> SELECT c.CustomerID,\n",
    "       c.CompanyName,\n",
    "       COUNT(o.OrderID) AS order_count\n",
    "FROM customers AS c\n",
    "LEFT JOIN orders AS o\n",
    "  ON o.CustomerID = c.CustomerID\n",
    "GROUP BY c.CustomerID, c.CompanyName\n",
    "ORDER BY order_count DESC, c.CompanyName;\n",
    "ORDER BY order_count DESC, c.CompanyName;\n",
    "\n",
    "CustomerID  CompanyName                           order_count\n",
    "----------  ------------------------------------  -----------\n",
    "SAVEA       Save-a-lot Markets                    31         \n",
    "ERNSH       Ernst Handel                          30         \n",
    "QUICK       QUICK-Stop                            28         \n",
    "FOLKO       Folk och fä HB                        19         \n",
    "HUNGO       Hungry Owl All-Night Grocers          19         \n",
    "BERGS       Berglunds snabbköp                    18         \n",
    "HILAA       HILARION-Abastos                      18         \n",
    "RATTC       Rattlesnake Canyon Grocery            18         \n",
    "BONAP       Bon app'                              17         \n",
    "FRANK       Frankenversand                        15         \n",
    "LEHMS       Lehmanns Marktstand                   15         \n",
    "WARTH       Wartian Herkku                        15         \n",
    "BOTTM       Bottom-Dollar Markets                 14         \n",
    "HANAR       Hanari Carnes                         14         \n",
    "KOENE       Königlich Essen                       14         \n",
    "LILAS       LILA-Supermercado                     14         \n",
    "LAMAI       La maison d'Asie                      14         \n",
    "WHITC       White Clover Markets                  14         \n",
    "AROUT       Around the Horn                       13         \n",
    "MEREP       Mère Paillarde                        13         \n",
    "QUEEN       Queen Cozinha                         13         \n",
    "LINOD       LINO-Delicateses                      12         \n",
    "REGGC       Reggiani Caseifici                    12         \n",
    "SUPRD       Suprêmes délices                      12         \n",
    "BLONP       Blondesddsl père et fils              11         \n",
    "GREAL       Great Lakes Food Market               11         \n",
    "RICAR       Ricardo Adocicados                    11         \n",
    "VAFFE       Vaffeljernet                          11         \n",
    "BSBEV       B's Beverages                         10         \n",
    "WANDK       Die Wandernde Kuh                     10         \n",
    "GODOS       Godos Cocina Típica                   10         \n",
    "ISLAT       Island Trading                        10         \n",
    "MAGAA       Magazzini Alimentari Riuniti          10         \n",
    "OLDWO       Old World Delicatessen                10         \n",
    "OTTIK       Ottilies Käseladen                    10         \n",
    "PICCO       Piccolo und mehr                      10         \n",
    "RICSU       Richter Supermarkt                    10         \n",
    "TORTU       Tortuga Restaurante                   10         \n",
    "VICTE       Victuailles en stock                  10         \n",
    "GOURL       Gourmet Lanchonetes                   9          \n",
    "QUEDE       Que Delícia                           9          \n",
    "SEVES       Seven Seas Imports                    9          \n",
    "SPLIR       Split Rail Beer & Ale                 9          \n",
    "WELLI       Wellington Importadora                9          \n",
    "CHOPS       Chop-suey Chinese                     8          \n",
    "EASTC       Eastern Connection                    8          \n",
    "FURIB       Furia Bacalhau e Frutos do Mar        8          \n",
    "LONEP       Lonesome Pine Restaurant              8          \n",
    "ANTON       Antonio Moreno Taquería               7          \n",
    "BLAUS       Blauer See Delikatessen               7          \n",
    "FAMIA       Familia Arquibaldo                    7          \n",
    "MAISD       Maison Dewey                          7          \n",
    "SIMOB       Simons bistro                         7          \n",
    "WILMK       Wilman Kala                           7          \n",
    "WOLZA       Wolski  Zajazd                        7          \n",
    "ALFKI       Alfreds Futterkiste                   6          \n",
    "CACTU       Cactus Comidas para llevar            6          \n",
    "DRACD       Drachenblut Delikatessen              6          \n",
    "FRANS       Franchi S.p.A.                        6          \n",
    "PERIC       Pericles Comidas clásicas             6          \n",
    "SANTG       Santé Gourmet                         6          \n",
    "TOMSP       Toms Spezialitäten                    6          \n",
    "TRADH       Tradição Hipermercados                6          \n",
    "COMMI       Comércio Mineiro                      5          \n",
    "FOLIG       Folies gourmandes                     5          \n",
    "GALED       Galería del gastrónomo                5          \n",
    "HUNGC       Hungry Coyote Import Store            5          \n",
    "MORGK       Morgenstern Gesundkost                5          \n",
    "OCEAN       Océano Atlántico Ltda.                5          \n",
    "PRINI       Princesa Isabel Vinhos                5          \n",
    "RANCH       Rancho grande                         5          \n",
    "ROMEY       Romero y tomillo                      5          \n",
    "VINET       Vins et alcools Chevalier             5          \n",
    "ANATR       Ana Trujillo Emparedados y helados    4          \n",
    "DUMON       Du monde entier                       4          \n",
    "LACOR       La corne d'abondance                  4          \n",
    "LETSS       Let's Stop N Shop                     4          \n",
    "SPECD       Spécialités du monde                  4          \n",
    "THEBI       The Big Cheese                        4          \n",
    "BOLID       Bólido Comidas preparadas             3          \n",
    "CONSH       Consolidated Holdings                 3          \n",
    "FRANR       France restauration                   3          \n",
    "LAUGB       Laughing Bacchus Wine Cellars         3          \n",
    "NORTS       North/South                           3          \n",
    "THECR       The Cracker Box                       3          \n",
    "TRAIH       Trail's Head Gourmet Provisioners     3          \n",
    "GROSR       GROSELLA-Restaurante                  2          \n",
    "LAZYK       Lazy K Kountry Store                  2          \n",
    "CENTC       Centro comercial Moctezuma            1          \n",
    "FISSA       FISSA Fabrica Inter. Salchichas S.A.  0          \n",
    "PARIS       Paris spécialités                     0  \n",
    "\n",
    "3.\n",
    "sqlite> SELECT DISTINCT c.CompanyName\n",
    "FROM customers AS c\n",
    "JOIN orders AS o\n",
    "  ON o.CustomerID = c.CustomerID\n",
    "JOIN OrderDetails AS od\n",
    "  ON od.OrderID = o.OrderID\n",
    "JOIN products AS p\n",
    "  ON p.ProductID = od.ProductID\n",
    "WHERE p.ProductName = 'Chai'\n",
    "ORDER BY c.CompanyName;\n",
    "CompanyName                 \n",
    "----------------------------\n",
    "Berglunds snabbköp          \n",
    "Blondesddsl père et fils    \n",
    "Bottom-Dollar Markets       \n",
    "Chop-suey Chinese           \n",
    "Die Wandernde Kuh           \n",
    "Du monde entier             \n",
    "Eastern Connection          \n",
    "Godos Cocina Típica         \n",
    "Great Lakes Food Market     \n",
    "HILARION-Abastos            \n",
    "Hungry Owl All-Night Grocers\n",
    "LINO-Delicateses            \n",
    "La maison d'Asie            \n",
    "Lehmanns Marktstand         \n",
    "Lonesome Pine Restaurant    \n",
    "Mère Paillarde              \n",
    "North/South                 \n",
    "Pericles Comidas clásicas   \n",
    "Princesa Isabel Vinhos      \n",
    "QUICK-Stop                  \n",
    "Queen Cozinha               \n",
    "Rattlesnake Canyon Grocery  \n",
    "Save-a-lot Markets          \n",
    "Seven Seas Imports          \n",
    "Suprêmes délices            \n",
    "The Cracker Box             \n",
    "Tortuga Restaurante         \n",
    "Wartian Herkku              \n",
    "Wellington Importadora      \n",
    "Wilman Kala                 \n",
    "Wolski  Zajazd  \n",
    "\n",
    "4. \n",
    "sqlite> SELECT OrderID, CustomerID, OrderDate\n",
    "FROM orders\n",
    "WHERE ShippedDate IS NULL\n",
    "ORDER BY OrderDate;\n",
    "OrderID  CustomerID  OrderDate              \n",
    "-------  ----------  -----------------------\n",
    "11008    ERNSH       1998-04-08 00:00:00.000\n",
    "11019    RANCH       1998-04-13 00:00:00.000\n",
    "11039    LINOD       1998-04-21 00:00:00.000\n",
    "11040    GREAL       1998-04-22 00:00:00.000\n",
    "11045    BOTTM       1998-04-23 00:00:00.000\n",
    "11051    LAMAI       1998-04-27 00:00:00.000\n",
    "11054    CACTU       1998-04-28 00:00:00.000\n",
    "11058    BLAUS       1998-04-29 00:00:00.000\n",
    "11059    RICAR       1998-04-29 00:00:00.000\n",
    "11061    GREAL       1998-04-30 00:00:00.000\n",
    "11062    REGGC       1998-04-30 00:00:00.000\n",
    "11065    LILAS       1998-05-01 00:00:00.000\n",
    "11068    QUEEN       1998-05-04 00:00:00.000\n",
    "11070    LEHMS       1998-05-05 00:00:00.000\n",
    "11071    LILAS       1998-05-05 00:00:00.000\n",
    "11072    ERNSH       1998-05-05 00:00:00.000\n",
    "11073    PERIC       1998-05-05 00:00:00.000\n",
    "11074    SIMOB       1998-05-06 00:00:00.000\n",
    "11075    RICSU       1998-05-06 00:00:00.000\n",
    "11076    BONAP       1998-05-06 00:00:00.000\n",
    "11077    RATTC       1998-05-06 00:00:00.000\n",
    "5.\n",
    "  SELECT c.CustomerID,\n",
    "         c.CompanyName,\n",
    "         COUNT(o.OrderID) AS order_count\n",
    "  FROM customers AS c\n",
    "  JOIN orders AS o\n",
    "    ON o.CustomerID = c.CustomerID\n",
    "  GROUP BY c.CustomerID, c.CompanyName\n",
    ")\n",
    "SELECT CustomerID, CompanyName, order_count\n",
    "FROM counts\n",
    "WHERE order_count = (SELECT MAX(order_count) FROM counts);\n",
    "\n",
    "CustomerID  CompanyName         order_count\n",
    "----------  ------------------  -----------\n",
    "SAVEA       Save-a-lot Markets  31    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your solutions. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences. Remember to also submit your SQL queries. No need to submit the text files for the programming exercises.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
